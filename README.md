# ğŸš€ MongoDB Agent - Open Source Distribution

**Version:** 1.0.0  
**License:** MIT  
**Package:** mongodb-agent

A powerful AI-powered agent for querying MongoDB databases using natural language. Built with LangGraph and supporting multiple LLM providers.

---

## ğŸ“¦ What's Inside?

```
mongodb-agent-ai/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ LICENSE                            # MIT License
â”œâ”€â”€ QUICK_START.md                     # 5-minute setup guide  
â”œâ”€â”€ setup.sh                           # Automated setup script
â”œâ”€â”€ start_custom_server.sh             # Server start script
â”œâ”€â”€ .env.template                      # Configuration template
â”œâ”€â”€ mongodb_agent-1.0.0-py3-none-any.whl  # Package wheel
â”œâ”€â”€ docs/                              # Documentation
â”‚   â”œâ”€â”€ USER_GUIDE.md                  # Complete user guide
â”‚   â”œâ”€â”€ API_REFERENCE.md               # API documentation
â”‚   â”œâ”€â”€ CONFIGURATION.md               # Configuration guide
â”‚   â””â”€â”€ TROUBLESHOOTING.md             # Common issues
â”œâ”€â”€ examples/                          # Example scripts
â”‚   â”œâ”€â”€ basic_query.py                 # Simple query
â”‚   â”œâ”€â”€ batch_queries.py               # Batch processing
â”‚   â””â”€â”€ custom_integration.py          # Integration example
â””â”€â”€ semantic_models/                   # YAML semantic models
    â””â”€â”€ example_collection.yaml        # Example model
```

---

## âš¡ Quick Start (3 Steps)

### Step 1: Install
```bash
pip install mongodb_agent-1.0.0-py3-none-any.whl
```

### Step 2: Configure
```bash
# Copy template and add your credentials
cp .env.template .env
nano .env  # Edit with your LLM and MongoDB credentials
```

### Step 3: Run
```bash
# Start MCP server (for Claude Desktop integration)
python3 -m mongodb_agent.cli server --port 8000

# OR start REST API server (for HTTP/API access)
python3 -m mongodb_agent.cli server --port 8000 --mode rest
```

---

## ğŸ¯ Features

- ğŸ¤– **Natural Language Queries** - Ask questions in plain English
- ğŸ”Œ **Multiple LLM Providers** - OpenAI, Azure OpenAI, Anthropic Claude
- ğŸ“Š **Semantic Models** - Define your MongoDB schema in YAML (local files or Weaviate)
- ğŸš€ **Model Context Protocol (MCP)** - Integrate with Claude Desktop
- ğŸŒ **REST API** - HTTP endpoints for easy integration
- ğŸ’¾ **Token Caching** - Efficient OAuth token management
- ğŸ¨ **Flexible Configuration** - Environment variables or config files
- ğŸ”€ **Dual MongoDB Modes** - Direct PyMongo or MCP Protocol

---

## ğŸ“‹ Requirements

- **Python**: 3.9 or higher
- **MongoDB**: MongoDB instance (local or remote)
- **LLM API**: OpenAI, Azure OpenAI, or Anthropic API key
- **Optional**: MCP-compatible client (e.g., Claude Desktop)

---

## ğŸ”§ Configuration

### LLM Providers

The agent supports multiple LLM providers:

**OpenAI (Easiest)**
```bash
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-your-key-here
OPENAI_MODEL=gpt-4o-mini
```

**Azure OpenAI**
```bash
LLM_PROVIDER=azure
AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com
AZURE_OPENAI_API_KEY=your-key
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o-mini
```

**Anthropic Claude**
```bash
LLM_PROVIDER=anthropic
ANTHROPIC_API_KEY=your-key
```

### MongoDB Connection

**Via MCP (Recommended)**
```bash
MONGODB_MCP_ENDPOINT=http://localhost:3000/mongodb/query
MONGODB_CLIENT_ID=your-client-id
MONGODB_CLIENT_SECRET=your-client-secret
```

**Direct Connection**
```bash
MONGODB_URI=mongodb://localhost:27017
MONGODB_DATABASE=your_database
```

---

## ğŸ“š Documentation

- **[QUICK_START.md](./QUICK_START.md)** - Get started in 5 minutes
- **[docs/USER_GUIDE.md](./docs/USER_GUIDE.md)** - Complete usage guide
- **[docs/API_REFERENCE.md](./docs/API_REFERENCE.md)** - API endpoints
- **[docs/CONFIGURATION.md](./docs/CONFIGURATION.md)** - Configuration options
- **[docs/TROUBLESHOOTING.md](./docs/TROUBLESHOOTING.md)** - Common issues

---

## ğŸ’¡ Example Usage

### Python API
```python
from mongodb_agent import MongoDBAgent, Config

# Configure
config = Config(
    llm_provider="openai",
    openai_api_key="your-key",
    mongodb_mcp_endpoint="http://localhost:3000/mongodb/query"
)

# Create agent
agent = MongoDBAgent(config)

# Query
result = agent.query(
    question="Show me all orders from last month",
    yaml_file_name="orders_semantic_model.yaml"
)

print(result["query_result"])
```

### REST API
```bash
curl -X POST http://localhost:8000/api/mongodb \\
  -H "Content-Type: application/json" \\
  -d '{
    "question": "Show me all orders from last month",
    "yaml_file_name": "orders_semantic_model.yaml"
  }'
```

### Claude Desktop Integration
```json
{
  "mcpServers": {
    "mongodb-agent": {
      "command": "python3",
      "args": ["-m", "mongodb_agent.cli", "server", "--port", "8000"]
    }
  }
}
```

---

## ğŸ› ï¸ Semantic Models

Define your MongoDB schema in YAML format:

```yaml
collection_info:
  database: "myapp"
  schema_name: "orders"
  
collections:
  orders:
    name: orders
    description: "Customer orders"
    fields:
      _id:
        data_type: "ObjectId"
        description: "Order ID"
      orderDate:
        data_type: "date"
        description: "Order date"
      totalAmount:
        data_type: "number"
        description: "Total order amount"
```

See `semantic_models/example_collection.yaml` for a complete example.

---

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Submit a pull request

---

## ğŸ“„ License

MIT License - see LICENSE file for details

---

## ğŸ†˜ Support

- **Issues**: [GitHub Issues](https://github.com/your-org/mongodb-agent/issues)
- **Documentation**: See `docs/` folder
- **Examples**: See `examples/` folder

---

## ğŸ‰ Acknowledgments

Built with:
- [LangGraph](https://github.com/langchain-ai/langgraph) - Agent orchestration
- [LangChain](https://github.com/langchain-ai/langchain) - LLM framework
- [Model Context Protocol](https://modelcontextprotocol.io) - Claude integration

---

## ğŸ“Š Architecture

```mermaid
flowchart TB
    User["ğŸ‘¤ User Query<br/>(Natural Language)"]
    
    subgraph Agent["ğŸ¤– MongoDB Agent (LangGraph State Machine)"]
        Ingress["ğŸšª Ingress<br/>(Initialize State)"]
        Selector["ğŸ“‹ Selector<br/>(Load Schema + Generate Query)"]
        Executor["â–¶ï¸ Query Executor<br/>(Execute MongoDB Query)"]
        Router{"ğŸ”€ Router<br/>(Check Result)"}
        Refiner["ğŸ”§ Query Refiner<br/>(Fix Query via LLM)"]
        Parser["ğŸ“ Output Parser<br/>(Format to Natural Language)"]
    end
    
    subgraph SemanticSource["ğŸ“š Semantic Model Source"]
        LocalYAML["ğŸ“„ Local YAML Files<br/>(Default)"]
        Weaviate["ğŸ” Weaviate Vector DB<br/>(Optional)"]
    end
    
    subgraph LLM["ğŸ§  LLM Provider"]
        OpenAI["OpenAI"]
        AzureOpenAI["Azure OpenAI"]
        Claude["Anthropic Claude"]
    end
    
    subgraph MongoRouter["ğŸ”„ MongoDB Connection"]
        MCPClient["ğŸ” MCP Client<br/>(OAuth2)"]
        DirectClient["ğŸ”— Direct Client<br/>(PyMongo)"]
    end
    
    MongoDB[("ğŸƒ MongoDB<br/>Database")]
    Result["âœ… Final Result<br/>(Natural Language)"]
    
    User --> Ingress
    Ingress --> Selector
    Selector --> Executor
    Executor --> Router
    Router -->|"âœ… Success"| Parser
    Router -->|"âŒ Error"| Refiner
    Router -->|"ğŸ’€ Fatal Error"| Result
    Refiner --> Executor
    Parser --> Result
    
    Selector -.->|"1. Load Schema<br/>2. Generate Query"| SemanticSource
    Selector -.->|"Generate Pipeline"| LLM
    Refiner -.->|"Fix Query"| LLM
    Parser -.->|"Format Output"| LLM
    
    Executor --> MongoRouter
    MCPClient --> MongoDB
    DirectClient --> MongoDB
    
    style User fill:#e1f5ff
    style Agent fill:#fff4e1
    style SemanticSource fill:#f0f0f0
    style LLM fill:#e8f5e9
    style MongoRouter fill:#fce4ec
    style MongoDB fill:#c8e6c9
    style Result fill:#e1f5ff
```

### Architecture Flow

1. **User Query** â†’ **Ingress** - Initialize agent state with user question
2. **Ingress** â†’ **Selector** - Loads semantic model (schema) from Local YAML or Weaviate, then uses LLM to generate MongoDB aggregation pipeline
3. **Selector** â†’ **Query Executor** - Executes the generated MongoDB query via:
   - **MCP Client** (OAuth2) - For Model Context Protocol integration
   - **Direct Client** (PyMongo) - For direct MongoDB connection
4. **Query Executor** â†’ **Router** - Checks execution result:
   - âœ… **Success** â†’ Go to Output Parser
   - âŒ **Error** (recoverable) â†’ Go to Query Refiner
   - ğŸ’€ **Fatal Error** â†’ Return error to user
5. **Query Refiner** â†’ **Query Executor** - LLM fixes the query and retries (max retry limit: 1)
6. **Output Parser** â†’ **Result** - LLM converts raw MongoDB results to natural language
7. **Return** - Final answer delivered to user

---

**Made with â¤ï¸ by the MongoDB Agent Team**
